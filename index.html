
<!DOCTYPE html>
<html lang="en">
    
 <head> 
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
    <link rel="stylesheet" href="style.css">
    <link href='https://fonts.googleapis.com/css?family=Montserrat' rel='stylesheet'>
    <title>Project | Ensemble Methods</title>
</head>
<body style="background-color:#f5f5f5">
    
    <div class="d-flex h-100 align-items-center justify-content-start">
        <div class="main-style">
            
                    <h1 class="display-1" class="lead">Wearable Device Data for Predicting Physical Activity States</h1>
                    <h4 class="display-4 left">Summary & Results</h4>
                    <p> The goal of this project is to quantify to what extent the data generated by wearable devices such as Apple Watch and Fitbit is able to measure
                        physical activity accurately, similarly to <a href="https://www.researchsquare.com/article/rs-17022/v1"> Fuller et al's study </a>, from which data is obtained. Furthermore,
                        we are trying to replicate those results, and try more classification methods to observe the performance of individual models and attempt to 
                        increase accuracy via ensemble methods. In the original study, it seems that experiments were done using all of the data at once, using the device
                        as a binary feature (Apple Watch and Fitbit) which yielded improved accuracy for Fitbit's datapoints in contrast to Apple Watch's. However, this
                        discrepancy might be due to a slight imbalance in the dataset for those two categories, which is why we first looked at the overall accuracy and then 
                        perform individual experiments for the two datasets, and obtained no significant accuracy differences between both devices' data. Moreover, we used a larger
                        test size proportion (5-fold stratified shuffled validation vs 10-fold). With respect to decision trees, we were able to outperform the original study's accuracy (41%-62% vs 77%) by
                        using hyperparameter optimization alone with Optuna. A K-Neighbors classifier obtained similar results. With respect to random forests, we obtained 86% overall
                        accuracy vs 81%-90% of the original study. Finally, the best accuracy in the original study was obtained with rotation forests (82%-89%) and we obtained 86%
                        with xgboost's gradient boosting classifier. However, spliting the data by device yielded 83% accuracy for both devices. This means that more data overall
                        increases the accuracy of the predictions, as could be expected, but that there's no real difference between both devices' data quality. The fact that 
                        different results for Apple Watch and Fitbit data may occur in a machine learning experiment on all the data combined could be not be related to the measurements 
                        of the device. In general, this results show that both devices are reasonably reliable in measuring data that can be used to infer the activity state of the person
                        wearing the device. 
                    </p>
            
            <h4 class="display-4 left">Conclusions</h4>
                    <p> There is a strong potential for health related applications based on data obtained in wearable devices. The accuracy of predictions is likely
                        to be improved not by adding more features but by training on larger data samples. Eliminating some features from the original data did not 
                        decrease accuracy significantly, but training on separate, smaller datasets, did. 
                    </p>
                        
            <hr>
                   
            
        </div>  
    </div>
    
     <div class="d-flex h-100 align-items-center justify-content-start">
        <div class="main-style">
                    
                    <h3 class="display-3 left">Exploratory Data Analysis</h3>

                    
            
                    <p>All of the fundamental procedures to understand the data is done through Pandas Profiling library and available 
                        <a href="https://sctueme.github.io/WebEDAforActSt/"> here</a>. In addition to the usual obligated EDA, we provide some visualizations
                        to understand the distributions across each activity state (for a total of 6) of two of the most important measurements in wearable devices: 
                        calories and heart rate. It seems that Apple Watch bivariate distributions for these variables are more compact and less sensitive to activity state.  
                        It is important to keep in mind that some measurements might vary widely accross states; for example, after running for a long time, heart rate
                        will keep its measurment at a high level even though the runner has stopped. Moreover, data from wearable commercial devices might not be accurate 
                        against medical devices, but the actual value obtained from the measurements is not necessarily to measure heart rate (or other related variables)
                        accurately, but to extract predictive power from them. 
                        
                                   
                                    <img src="img/dist0.png" class="img-responsive" alt="Max-height 5%">
                                   

                    <figure>
                        <img src="img/dist0.png" class="img-fluid" alt="Responsive image">
                        <img src="img/dist1.png" class="img-fluid" alt="Responsive image">
                        <img src="img/dist2.png" class="img-fluid" alt="Responsive image">
                        <img src="img/dist3.png" class="img-fluid" alt="Responsive image">
                        <img src="img/dist4.png" class="img-fluid" alt="Responsive image">
                        <img src="img/dist5.png" class="img-fluid" alt="Responsive image">
                        <figcaption>Bivariate distributions of calories and heart rate device measurements.</figcaption>
                    </figure>
                               </div>  
                        
                    </p>
            
                    <hr>
                    
     </div>  
    </div>
   
   <div class="d-flex h-100 align-items-center justify-content-center">
          <div class="main-style">
                      <h3 class="display-3 left">Classification</h3>
                      <p> Methods used for this task were Gaussian Naive Bayes, Decision Trees, K-Neighbors, Random Forest, Weighted and Unweighted Voting 
                          (with Gaussian Naive Bayes, Decision Trees, and K-Neighbors as base estimators, and weights defined proportionaly by previous performance),
                          Adaptative Boosting (with Gaussian Naive Bayes and Decision Trees for base estimators), and Gradient Boosting (XGBoost). We used 5-fold
                          stratified (and shuffled) cross validation.
                          Overall accuracy for each model is ploted below:
                          
                         <figure>
                       
                        <img src="img/accs.png" class="img-fluid" alt="Responsive image">
                 
                        <figcaption>Performance of both individual and ensemble ML methods.</figcaption>
                    </figure>
                      </p>
                      <h4 class="display-4 left">Beyond the Confusion Matrix</h4>
                      <p>Although it is standard practice to include a confusion matrix after a classification task, we skip this part as there are 6 different
                          classes and we could compress more information (not quantitatively but qualitatively) in the following visualizations, since we can
                          observe for 3 different variables (could be off course, any others) how is the predicted result deviated from the ground truth result. 
                          For example, high-level activity was predicted for true low-level activity with a high calory calculation (which is performed with proprietary
                          methods for each device) where as with heart rate, this happened across all measurements. 
                      </p>
                     
                      <p>
                      <figure>
                        <img src="img/truevspredictedheart_rate.png" class="img-fluid" alt="Responsive image">
                        <img src="img/truevspredictedsteps.png" class="img-fluid" alt="Responsive image">
                        <img src="img/truevspredictedcalories.png" class="img-fluid" alt="Responsive image">
                      </figure>
                      </p>
                    
          </div>
    </div>
    
    
    
    
    
    
    
</body>
</html>
