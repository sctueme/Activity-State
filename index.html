
<!DOCTYPE html>
<html lang="en">
    
 <head> 
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
    <link rel="stylesheet" href="style.css">
    <link href='https://fonts.googleapis.com/css?family=Montserrat' rel='stylesheet'>
    <title>Project | Ensemble Methods</title>
</head>
<body style="background-color:#f5f5f5">
    
    <div class="d-flex h-100 align-items-center justify-content-start">
        <div class="main-style">
            
                    <h1 class="display-1" class="lead">Wearable Device Data for Predicting Physical Activity States</h1>
                    <h4 class="display-4 left">Summary & Results</h4>
                    <p> The goal of this project is to quantify to what extent the data generated by wearable devices such as Apple Watch and Fitbit is able to measure
                        physical activity accurately, similarly to <a href="https://www.researchsquare.com/article/rs-17022/v1"> Fuller et al's study </a>, from which data is obtained. Furthermore,
                        we are trying to replicate those results, and try more classification methods to observe the performance of individual models and attempt to 
                        increase accuracy via ensemble methods. In the original study, it seems that experiments were done using all of the data at once, using the device
                        as a binary feature (Apple Watch and Fitbit) which yielded improved accuracy for Fitbit's datapoints in contrast to Apple Watch's. However, this
                        discrepancy might be due to a slight imbalance in the dataset for those two categories, which is why we first looked at the overall accuracy and then 
                        perform individual experiments for the two datasets, and obtained no significant accuracy differences between both devices' data. Moreover, we used a larger
                        test size proportion (5-fold stratified shuffled validation vs 10-fold). With respect to decision trees, we were able to outperform the original study's accuracy (41%-62% vs 77%) by
                        using hyperparameter optimization alone with Optuna. A K-Neighbors classifier obtained similar results. With respect to random forests, we obtained 86% overall
                        accuracy vs 81%-90% of the original study. Finally, the best accuracy in the original study was obtained with rotation forests (82%-89%) and we obtained 86%
                        with xgboost's gradient boosting classifier. However, spliting the data by device yielded 83% accuracy for both devices. This means that more data overall
                        increases the accuracy of the predictions, as could be expected, but that there's no real difference between both devices' data quality. The fact that 
                        different results for Apple Watch and Fitbit data may occur in a machine learning experiment on all the data combined could be not be related to the measurements 
                        of the device. In general, this results show that both devices are reasonably reliable in measuring data that can be used to infer the activity state of the person
                        wearing the device. 
                    </p>
            
            <h4 class="display-4 left">Conclusions</h4>
                    <p> There is a strong potential for health related applications based on data obtained in wearable devices. The accuracy of predictions is likely
                        to be improved not by adding more features but by training on larger data samples. Eliminating some features from the original data did not 
                        decrease accuracy significantly, but training on separate, smaller datasets, did. 
                    </p>
                        
            <hr>
                   
            
        </div>  
    </div>
    
     <div class="d-flex h-100 align-items-center justify-content-start">
        <div class="main-style">
                    
                    <h3 class="display-3 left">Exploratory Data Analysis</h3>

                    
            
                    <p>All of the fundamental procedure to understand the data is done through Pandas Profiling library and available 
                        <a href="https://sctueme.github.io/WebEDAforActSt/"> here</a>. In addition to the usual "mandatory" EDA, we provide some visualizations
                        to understand the distributions across each activity state (for a total of 6) of two of the most important measurements in wearable devices: 
                        calories and heart rate. It seems that Apple Watch bivariate distributions for these variables are more compact and less sensitive to activity state.  
                        It is important to keep in mind that some measurements might vary widely accross states; for example, after running for a long time, heart rate
                        will keep its measurment at a high level even though the runner has stopped. Moreover, data from wearable commercial devices might not be accurate 
                        against medical devices, but the actual value obtained from the measurements is not necessarily to measure heart rate (or other related variables)
                        accurately, but to extract predictive power from them. 
                    <figure>
                        <img src="img/dist0.png" class="img-fluid" alt="Responsive image">
                        <img src="img/dist1.png" class="img-fluid" alt="Responsive image">
                        <img src="img/dist2.png" class="img-fluid" alt="Responsive image">
                        <img src="img/dist3.png" class="img-fluid" alt="Responsive image">
                        <img src="img/dist4.png" class="img-fluid" alt="Responsive image">
                        <img src="img/dist5.png" class="img-fluid" alt="Responsive image">
                        <figcaption>Bivariate distributions of calories and heart rate device measurements.</figcaption>
                    </figure>
                        
                        
                    </p>
            
                    <p> To clean the data, we simply dropped the columns (features) that had too many missing values or that were irrelevant for the classification 
                        task. For example, the amount of beer made in the recipe tells us no information about what style the recipe belongs to. The rows
                        with missing values after keeping the most relevant features were dropped as well. The reason for not imputing is that we are interested 
                        in using this data for experimentation on machine learning modeling, rather than trying to extract patterns for a practical application. 
                        Also, Original Gravity and Final Gravity are highly correlated, so one of them was dropped.
                             
                    </p>
            
                    <p> A good way of understanding the intricacies of the beer styles represented in the recipe samples, is the following dendrogram, since it
                        provides a way of quickly visualizing similarity between beer styles of interest. This was made by taking the beer styles as vectors
                        on euclidean space described by the mean of the feature for each class corresponding to each entry. Then, single-linkage hierarchical clustering
                        with euclidean metrics was applied.  
                    <figure>
                        <img src="ML-data-exp/ml-exp/img/dendro.png" class="img-fluid" alt="Responsive image">
                        <figcaption>Dendrogram of beer styles (Dataset-1). The closer the connection of beerstyles to 0 on the X axis, the more similar they are.
                        Labels are colored according to a uniform 4-partition of the 'Color' feature range.</figcaption>
                    </figure>
                    </p>
            
                    <p> To show the difficulty of this classification task, due to the fact that there is simply not much data to help distinguish between classes, 
                        we illustrate the overlap between the Dataset-2 (binary) classes on the features that were kept with their pairwise (2D) projections.
                        
                    <figure>
                        <img src="ML-data-exp/ml-exp/img/pairs2.png" class="img-fluid" alt="Responsive image">
                        <figcaption>Pairwise projections of the Dataset-2 classes.</figcaption>
                    </figure>
                        
                        
                    </p>
            
                    <p> Moreover, we show how similar distributions between classes are when it comes to variables that usually makes beer styles somewhat 
                        different for the consumer: alcohol content and color.
                        
                    <figure>
                        <img src="ML-data-exp/ml-exp/img/abvdist.png" class="img-fluid" alt="Responsive image">
                        <img src="ML-data-exp/ml-exp/img/colordist.png" class="img-fluid" alt="Responsive image">
                        <figcaption>Pairwise projections of the Dataset-2 classes.</figcaption>
                    </figure>
                        
                        
                    </p>
            
                    <hr>
                    
        </div>  
    </div>
   
   <div class="d-flex h-100 align-items-center justify-content-center">
          <div class="main-style">
                      <h3 class="display-3 left">Performance</h3>
                      <p> For all the methods tested, we use hyperparameter optimization to show that the accuracy is bounded
                          not by model complexity or efficiency but by the data itself. This is the part where it becomes clear
                          that at some stage it becomes pointless to try and apply more complex machine learning models to the problem at hand.
                      </p>
                      <h4 class="display-4 left">Linear Classifiers</h4>
                      <p>Formally speaking, the Stochastic Gradient Descent method is an optimization algorithm (it seeks to minimize some function) and not per se 
                          a model for classification. However, scikit learn's SGDClassifier is an instance in which we can select hyperparameters that will yield
                          a classification model as a particular case. Since we are using hyperparameter optimization tools, we might as well select this method
                          first. In general, what linear classifiers do is try to segment the space the data is embedded in, into regions that will correspond to the 
                          classes in our task, using lines, planes or hyperplanes as separators. For Dataset-1, we have only 7 features for 47 different classes. 
                          That could be enought provided that the data is
                          very clearly separated in space, which is not the case in this example, as we can see from the pairwise projection plots 
                          (of the simplified
                          Dataset-2) above.
                      </p>
                      <h4 class="display-4 left">Non-linear Support Vector Machines</h4>
                      <p>Roughly speaking, what suppor vector machines do is find hyperplanes in space that separate datapoints into regions associated with classes, very much like 
                         linear classifiers, except that this regions are found in the space resulting form applying a non-linear transformation to the original 
                          data feature space (if a SVM has a linear kernel, then it is a linear classifier). Such transformation is applied with the purpose of mapping
                          datapoints into regions that are more easily separable than they were in the original space.
                           
                      </p>
                      <h4 class="display-4 left">Neural Networks<h4>
                      <p> Finally, a neural network is a concatenation of linear and non-linear transormations on the original space that make up a highly
                          non-linear model for decision boundaries on the resulting space. Hence, this method adds a lot of complexity and it should be perfoming the best
                          in terms of accuracy. In practice, there is always a trade off between complexity and efficiency, since more complex algorithms will 
                          usually take longer to run. For example, if we are faced with a binary classification task on data that is clearly separable, there is no
                          reason to use a neural network on the first attempt, since linear classifiers are very likely to work well. 
                      </p>
                      
                          <h4 class="display-4 left">Hyperparameter Optimization<h4>    
                      <p> The performance, efficiency and complexity of machine learning models is mainly set by the hyperparameters that we choose to use. 
                          For simple datasets, sometimes the default parameters are good enough to produce a decent outcome. But when data is not so simple, 
                          we are faced with making the decision of selecting not only a model that can perform as accurately as possible, but that is reasonably 
                          fast for our purposes. Moreover, for large problems, trial and error (grid and random search methods) can be a very long and useless way 
                          of selecting models and hyperparameters.
                          For the latter, it's recommendable to use some form of optimization method. We use 3 different methods from the Python libraries 
                          scikit-optimize, Hyperopt, and Optuna.   
                      </p>
                      
                      <h4 class="display-4 left">Results<h4>    
                      <p>
                      For Dataset-1 model complexity helped increase the accuracy especially from the SGD (stochastic gradient descent linear classifier) to 
                          the SVC (support vector machine) methods, and less so from SVC to the NN (neural network) method, even though the NN is much more complex.
                          Moreover, for several iterations it was necessary to interrupt the hyperparameter search (due to running times), and therefore we cannot be 
                          certain that the improvement obtained by going from SVC to NN is significant. Hence, we can infer that increasingly complex models will 
                          improve decreasingly less due to the fact that the data has too many classes and not enough information to make out significant differences 
                          between them. For the Dataset-2 overall accuracy was increased (which is expected since it became a simplified binary classification task) but
                          there seems to be no improvement from SVC to NN, and very little improvement from SGD to SVC. At this point, since method complexity with
                          hyperparameter optimization is failing to improve accuracy scores, we can conclude that it is pointless to keep trying even more complex models,
                          since the data yields just enough information for the obtained accuracy scores in the different methods. 
                      <figure>
                        <img src="ML-data-exp/ml-exp/img/confusion.png" class="img-fluid" alt="Responsive image">
                        <figcaption>Dataset-2 confusion matrix.</figcaption>
                      </figure>     
                          
                      <figure>
                        <img src="ML-data-exp/ml-exp/img/t1_mplot.png" class="img-fluid" alt="Responsive image">
                        <figcaption>Dataset-1 Model Performance.</figcaption>
                      </figure>
                          
                      <figure>
                        <img src="ML-data-exp/ml-exp/img/t2_mplot.png" class="img-fluid" alt="Responsive image">
                        <figcaption>Dataset-2 Model Performance.</figcaption>
                      </figure>
                          
                      <figure>
                        <img src="ML-data-exp/ml-exp/img/t1plot.png" class="img-fluid" alt="Responsive image">
                        <figcaption>Dataset-1 Optimization Algorithms Performance.</figcaption>
                      </figure>
                          
                      <figure>
                        <img src="ML-data-exp/ml-exp/img/t2plot.png" class="img-fluid" alt="Responsive image">
                        <figcaption>Dataset-2 Optimization Algorithms Performance.</figcaption>
                      </figure>
                          
                     
                      </p>
                      <hr>
          </div>
    </div>
    
    
    
    
    
    
    
</body>
</html>
